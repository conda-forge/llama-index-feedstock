{% set name = "llama-index" %}
{% set version = "0.12.22" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/llama_index-{{ version }}.tar.gz
  sha256: 6d9f83530cf1adefd2719509dc7ccfbda1fed92ccca030c8ffa3eb45ccc8973b

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - pip
    - poetry
    - poetry-core
  run:
    - python >={{ python_min }}
    - llama-index-cli >=0.4.1,<0.5.0
    - llama-index-indices-managed-llama-cloud >=0.4.0
    - llama-index-readers-llama-parse >=0.4.0
    - llama-index-agent-openai >=0.4.0,<0.5.0
    - llama-index-core >=0.12.22,<0.13.0
    - llama-index-embeddings-openai >=0.3.0,<0.4.0
    - llama-index-legacy >=0.9.48,<0.10.0
    - llama-index-llms-openai >=0.3.0,<0.4.0
    - llama-index-multi-modal-llms-openai >=0.4.0,<0.5.0
    - llama-index-program-openai >=0.3.0,<0.4.0
    - llama-index-question-gen-openai >=0.3.0,<0.4.0
    - llama-index-readers-file >=0.4.0,<0.5.0
    - nltk >3.8.1
  run_constrained:
    - langchain >=0.0.303
    - asyncpg >=0.29.0,<0.30.0
    - pgvector >=0.3.6,<1.0.0
    - psycopg-binary >=3.1.12,<4.0.0
    - optimum >=1.13.2,<2.0.0
    - onnxruntime >=1.11.0
    - datasets >=1.2.1
    - evaluate
    - protobuf >=3.20.1
    - sentencepiece *
    - transformers >=4.34.0,<5.0.0
    - guidance >=0.0.64,<1.0.0
    - lm-format-enforcer >=0.4.3,<0.5.0
    - jsonpath-ng >=1.6.0,<2.0.0
    - rank-bm25 >=0.2.2,<0.3.0
    - scikit-learn *
    - spacy >=3.7.1,<4.0.0


test:
  imports:
    - llama_index
  commands:
    - pip check
  requires:
    - pip
    - python {{ python_min }}

about:
  home: https://github.com/run-llama/llama_index
  summary: Interface between LLMs and your data
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - jan-janssen
    - pavelzw
