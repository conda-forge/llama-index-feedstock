{% set name = "llama-index" %}
{% set version = "0.10.6" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/llama_index-{{ version }}.tar.gz
  sha256: b31b7e1c1b148265ec84640906e83f8d6b37fbec3b9daa6f763a7597357209cc

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.8,<3.12
    - pip
    - poetry
    - poetry-core
  run:
    - llama-index-agent-openai >=0.1.0,<0.2.0
    - llama-index-core >=0.10.0,<0.11.0
    - llama-index-embeddings-openai >=0.1.0,<0.2.0
    - llama-index-legacy >=0.9.48,<0.10.0
    - llama-index-llms-openai >=0.1.0,<0.2.0
    - llama-index-multi-modal-llms-openai >=0.1.0,<0.2.0
    - llama-index-program-openai >=0.1.0,<0.2.0
    - llama-index-question-gen-openai >=0.1.0,<0.2.0
    - llama-index-readers-file >=0.1.0,<0.2.0
    - dirtyjson >=1.0.8,<2.0.0
    - networkx >=3.0
    - types-protobuf >=4.24.0,<5.0.0
    - sqlalchemy >=1.4.49
    - python >=3.8,<3.12
    - SQLAlchemy >=1.4.49
    - greenlet !=0.4.17
    - beautifulsoup4 >=4.12.2,<5.0.0
    - dataclasses-json
    - deprecated >=1.2.9.3
    - fsspec >=2023.5.0
    - httpx
    - nest-asyncio >=1.5.8,<2.0.0
    - nltk >=3.8.1,<4.0.0
    - numpy
    - openai >=1.1.0
    - pandas
    - tenacity >=8.2.0,<9.0.0
    - tiktoken >=0.3.3
    - typing-extensions >=4.5.0
    - typing_inspect >=0.8.0
    - requests >=2.31.0
    - aiostream >=0.5.2,<0.6.0
    - aiohttp >=3.8.6,<4.0.0
  run_constrained:
    - langchain >=0.0.303
    - asyncpg >=0.28.0,<0.29.0
    - pgvector >=0.1.0,<0.2.0
    - psycopg-binary >=3.1.12,<4.0.0
    - optimum >=1.13.2,<2.0.0
    - onnxruntime >=1.11.0
    - datasets >=1.2.1
    - evaluate
    - protobuf >=3.20.1
    - sentencepiece >=0.1.99,<0.2.0
    - transformers >=4.34.0,<5.0.0
    - guidance >=0.0.64,<1.0.0
    - lm-format-enforcer >=0.4.3,<0.5.0
    - jsonpath-ng >=1.6.0,<2.0.0
    - rank-bm25 >=0.2.2,<0.3.0
    - scikit-learn <1.3.0
    - spacy >=3.7.1,<4.0.0


test:
  imports:
    - llama_index
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/run-llama/llama_index
  summary: Interface between LLMs and your data
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - pavelzw
